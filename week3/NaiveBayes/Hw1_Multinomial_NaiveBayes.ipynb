{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multinomial_NaiveBayes 과제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData =[\n",
    "    (1, \"Chinese Beijing Chinese\", \"China\"),\n",
    "    (2, \"Chinese Chinese Shanhai\", \"China\"),\n",
    "    (3, \"Chinese Macao\", \"China\"),\n",
    "    (4, \"Tokyo Japan Chinese\", \"Japan\")\n",
    "]\n",
    "\n",
    "testingData = (5, \" Chinese Chinese Chinese Tokyo Japan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 단어들 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shanhai', 'tokyo', 'beijing', 'chinese', 'macao', 'japan']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vocab = list(set(([term for _ in trainingData\n",
    "        for term in _[1].lower().split()])))\n",
    "Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Chinese Beijing Chinese', 'China'), (2, 'Chinese Chinese Shanhai', 'China'), (3, 'Chinese Macao', 'China')] \n",
      " [(4, 'Tokyo Japan Chinese', 'Japan')]\n"
     ]
    }
   ],
   "source": [
    "chinaData = [vector for vector in trainingData if vector[2] == \"China\"]\n",
    "japaneseData = [vector for vector in trainingData if not vector[2] == \"China\"]\n",
    "print(chinaData, \"\\n\" ,japaneseData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words 만들기 trem frequency 매트릭스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {'chinese': 5, 'beijing': 1, 'shanhai': 1, 'macao': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "# defaultdict는 dict에 key가 없어도 자동으로 추가해서 만들어주는 역할이다.\n",
    "\n",
    "prior = list()\n",
    "\n",
    "Tct = defaultdict(int)\n",
    "for data in chinaData:  \n",
    "    for term in data[1].lower().split():\n",
    "        Tct[term] += 1\n",
    "\n",
    "_Tct = defaultdict(int)\n",
    "for data in japaneseData:  \n",
    "    for term in data[1].lower().split():\n",
    "        _Tct[term] += 1\n",
    "        \n",
    "print(Tct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 각 클래스에서 단어가 나올 확률 구하기 likelihood\n",
    "### laplacian smoothing 적용 -> freq + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "condProbC = defaultdict(float)\n",
    "_condProbC = defaultdict(float)\n",
    "\n",
    "countSum = sum(Tct.values())\n",
    "_countSum = sum(_Tct.values())\n",
    "\n",
    "for term, freq in Tct.items():\n",
    "    condProbC[term] = (freq+1)/(countSum + len(Vocab))\n",
    "\n",
    "for term, freq in _Tct.items():\n",
    "    _condProbC[term] = (freq+1)/(_countSum + len(Vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(defaultdict(float,\n",
       "             {'chinese': 0.42857142857142855,\n",
       "              'beijing': 0.14285714285714285,\n",
       "              'shanhai': 0.14285714285714285,\n",
       "              'macao': 0.14285714285714285}),\n",
       " defaultdict(float,\n",
       "             {'tokyo': 0.2222222222222222,\n",
       "              'japan': 0.2222222222222222,\n",
       "              'chinese': 0.2222222222222222}))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condProbC, _condProbC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사전확률 구하기 prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(trainingData)\n",
    "\n",
    "Nc = len(chinaData)\n",
    "PriorC = Nc/N\n",
    "\n",
    "_Nc = len(japaneseData)\n",
    "_PriorC = _Nc/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log 취해서 하기 : 곱연산이 더하기 연산으로 변화하고 0에 가까워지는 확률값을 보정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "China -8.10769031284391 0.00030121377997263 Japanese : -8.906681345001262 0.00013548070246744215\n"
     ]
    }
   ],
   "source": [
    "# P(C)multi(P(Tct|C)) ===> log(P(C)) + SUM(P(Tct|C))\n",
    "from math import log, exp\n",
    "\n",
    "# Prior Probability\n",
    "result = log(PriorC)\n",
    "_result = log(_PriorC)\n",
    "\n",
    "# joint probability => conditional independence\n",
    "for term in testingData[1].lower().split():\n",
    "    # multi -> log sum\n",
    "    result += log((Tct[term]+1)/(countSum+len(Vocab)))\n",
    "    _result += log((_Tct[term]+1)/(_countSum+len(Vocab)))\n",
    "\n",
    "# optimal classfier\n",
    "if result > _result:\n",
    "    print(\"China\", result, exp(result), \"Japanese :\", _result, exp(_result))\n",
    "else:\n",
    "    print(\"Japanese :\", _result, exp(_result), \"China :\", result, exp(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chinese의 weight가 높은데 3개나 들어있어 china로 class로 배정되었다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
