{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris.data -> features, iris.target -> labels\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- About data : https://www.kaggle.com/uciml/iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into test and train dataset, and use random_state=48\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Documentation for \"StandardScaler\" : https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet=np.column_stack((X_train, y_train))\n",
    "testSet=np.column_stack((X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).unique() # 3가지 종류가 있음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# mahalonobis 거리를 활용하기 위한 공분산행렬이다.\n",
    "cov_matrix = np.cov(X_train.T)\n",
    "\n",
    "def getDistance(p, instance1, instance2):\n",
    "    # p=1 : return Manhattan Distance\n",
    "    # p=2 : return Eucludean Distance\n",
    "    # p=3 : return Mahalonobis Distance\n",
    "    # p=4 : return Correlation Distance\n",
    "    if p == 1:\n",
    "        return distance.cityblock(instance1[:-1], instance2[:-1]) #cityblock이 manhattan거리이다.\n",
    "\n",
    "    elif p == 2:\n",
    "        return distance.euclidean(instance1[:-1], instance2[:-1])\n",
    "\n",
    "    elif p == 3:    \n",
    "        cov_matrix = np.cov(X_train.T)\n",
    "        return distance.mahalanobis(instance1[:-1], instance2[:-1], inv(cov_matrix))\n",
    "    \n",
    "    elif p == 4:\n",
    "        return distance.correlation(instance1[:-1], instance2[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(p, trainSet, testInstance, k):\n",
    "    \n",
    "    neighbors = list()\n",
    "    for i in range(len(trainSet)):\n",
    "        # trainSet의 index와 거리를 같이 저장한다.\n",
    "        neighbors.append((i, getDistance(p, trainSet[i], testInstance)))\n",
    "    \n",
    "    #이웃중에서 거리가 가장 짧은 k개만 뽑는다\n",
    "    return sorted(neighbors, key=lambda x:x[1])[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from collections import Counter\n",
    "\n",
    "def getResponse(neighbors):\n",
    "    # 0은 인덱스 1은 거리값\n",
    "    # 정답(class)값만 담고있는 리스트 생성\n",
    "    result = [trainSet[each[0]][-1] for each in neighbors]\n",
    "\n",
    "    # 가장 많이나온 정답(class)가 무엇인지 알려주기\n",
    "    counter = Counter(result)\n",
    "    vote = max(result, key=counter.get)\n",
    "\n",
    "    return vote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "    answer_count = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == testSet[i][-1]:\n",
    "            answer_count += 1\n",
    "\n",
    "    accuracy_score = answer_count / len(testSet)\n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3\n",
    "p = 2 # Euclidean distance\n",
    "\n",
    "def KNN(p, trainSet, testSet, k):\n",
    "    predictions=[]    \n",
    "    for i in range(len(testSet)):\n",
    "        neighbors = getNeighbors(p, trainSet, testSet[i], k)\n",
    "        result = getResponse(neighbors)\n",
    "        predictions.append(result)\n",
    "#         print(str(i) + ' > predicted : ' + str(result) + ', actual : ' + str(testSet[i][-1]))\n",
    "    accuracy = getAccuracy(testSet, predictions)\n",
    "    print('Accuracy: ' + str(accuracy) + '%')\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "KNN(p, trainSet, testSet, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 거리를 4가지 방법으로 해서 accuracy비교!\n",
    "### manhatan거리가 정확률이 제일 좋게 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.8444444444444444%\n",
      "Accuracy: 0.7111111111111111%\n"
     ]
    }
   ],
   "source": [
    "for p in range(1, 5):\n",
    "    KNN(p, trainSet, testSet, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 적절한 k 값 찾기\n",
    "### accuracy가 높았던 manhatan거리와 euclidean거리를 사용하도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manhatan\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.9333333333333333%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.9555555555555556%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.9111111111111111%\n",
      "k : 13\n",
      "euclidean\n",
      "Accuracy: 0.8666666666666667%\n",
      "Accuracy: 0.8666666666666667%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.9333333333333333%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.9111111111111111%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.8666666666666667%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.8888888888888888%\n",
      "Accuracy: 0.8888888888888888%\n",
      "k : 11\n"
     ]
    }
   ],
   "source": [
    "p = 1\n",
    "print(\"manhatan\")\n",
    "# for k in range(1, 10):\n",
    "k_value = [KNN(p, trainSet, testSet, k) for k in range(1, 20)]\n",
    "print(\"k :\", k_value.index(max(k_value)) + 1)\n",
    "p = 2\n",
    "print(\"euclidean\")\n",
    "k_value = [KNN(p, trainSet, testSet, k) for k in range(1, 20)]\n",
    "print(\"k :\", k_value.index(max(k_value)) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3개의 클래스라 3개가 제일 높을 줄 알았는데 훈련데이터에 따라 달라 k가 다른숫자일 때도 높게 나오기도 함을 볼 수 있다.\n",
    "#### 하지만 이렇게 하면 testSet에 오버피팅 된 하이퍼파라미터 k를 얻기 때문에 cross validation을 사용해본다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn 라이브러리 사용한 knn 구현\n",
    "# 적절한 k 값 찾기 - Cross Validation(cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3, p=2)\n",
    "# distance는 default값 : p=2\n",
    "# minkowski_distance - euclidean distance와 manhattan distance의 일반화\n",
    "# p=1 이면 manhattan p=2이면 euclidean\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn.score(X_test, y_test) # 내가 구현한 knn과 값이 똑같음을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1 [0.95454545 1.         0.95238095 0.95238095 1.        ]\n",
      "cv_scores mean:0.9718614718614719\n",
      "k = 2 [0.90909091 0.95454545 0.95238095 0.95238095 1.        ]\n",
      "cv_scores mean:0.9536796536796537\n",
      "k = 3 [0.95454545 0.95454545 0.95238095 0.95238095 1.        ]\n",
      "cv_scores mean:0.9627705627705628\n",
      "k = 4 [0.95454545 0.95454545 0.95238095 0.95238095 1.        ]\n",
      "cv_scores mean:0.9627705627705628\n",
      "k = 5 [0.95454545 0.95454545 0.95238095 0.95238095 1.        ]\n",
      "cv_scores mean:0.9627705627705628\n",
      "k = 6 [0.95454545 0.95454545 1.         0.95238095 1.        ]\n",
      "cv_scores mean:0.9722943722943723\n",
      "k = 7 [0.95454545 0.95454545 0.95238095 0.95238095 1.        ]\n",
      "cv_scores mean:0.9627705627705628\n",
      "k = 8 [0.90909091 0.95454545 0.95238095 0.95238095 1.        ]\n",
      "cv_scores mean:0.9536796536796537\n",
      "k = 9 [0.95454545 0.95454545 0.95238095 0.95238095 1.        ]\n",
      "cv_scores mean:0.9627705627705628\n",
      "k = 10 [0.90909091 0.95454545 1.         0.95238095 1.        ]\n",
      "cv_scores mean:0.9632034632034632\n",
      "k = 11 [0.95454545 0.95454545 1.         0.95238095 1.        ]\n",
      "cv_scores mean:0.9722943722943723\n",
      "k = 12 [0.95454545 0.95454545 1.         0.9047619  1.        ]\n",
      "cv_scores mean:0.9627705627705627\n",
      "k = 13 [0.95454545 0.95454545 1.         0.9047619  1.        ]\n",
      "cv_scores mean:0.9627705627705627\n",
      "k = 14 [0.86363636 0.95454545 0.95238095 0.9047619  1.        ]\n",
      "cv_scores mean:0.9350649350649352\n",
      "k = 15 [0.86363636 0.95454545 0.95238095 0.9047619  1.        ]\n",
      "cv_scores mean:0.9350649350649352\n",
      "k = 16 [0.86363636 0.95454545 0.95238095 0.9047619  1.        ]\n",
      "cv_scores mean:0.9350649350649352\n",
      "k = 17 [0.86363636 0.95454545 0.95238095 0.9047619  1.        ]\n",
      "cv_scores mean:0.9350649350649352\n",
      "k = 18 [0.86363636 0.95454545 0.95238095 0.9047619  1.        ]\n",
      "cv_scores mean:0.9350649350649352\n",
      "k = 19 [0.86363636 0.95454545 0.95238095 0.9047619  1.        ]\n",
      "cv_scores mean:0.9350649350649352\n",
      "k = 20 [0.86363636 0.95454545 0.9047619  0.9047619  1.        ]\n",
      "cv_scores mean:0.9255411255411256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "acc_list =[]\n",
    "\n",
    "for k in range(1, 21):\n",
    "    knn_cv = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "    cv_scores = cross_val_score(knn_cv, X_train, y_train, cv=5)\n",
    "\n",
    "    print(\"k =\", k, cv_scores)\n",
    "    print('cv_scores mean:{}'.format(np.mean(cv_scores)))\n",
    "    acc_list.append((k, np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 0.9722943722943723)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(acc_list, key=lambda x:x[1]) # k=6일 떄 accuracy가 제일 높게 나온다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid search library 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 6} 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#create new a knn model\n",
    "knn2 = KNeighborsClassifier()\n",
    "#create a dictionary of all values we want to test for n_neighbors\n",
    "param_grid = {'n_neighbors': np.arange(1, 21)}\n",
    "#use gridsearch to test all values for n_neighbors\n",
    "knn_gscv = GridSearchCV(knn2, param_grid, cv=5)\n",
    "#fit model to data\n",
    "knn_gscv.fit(X, y)\n",
    "\n",
    "print(knn_gscv.best_params_, knn_gscv.best_score_) # 내가 구한 값하고 같음을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k=6을 사용하여 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6, p=2)\n",
    "# distance는 default값 : p=2\n",
    "# minkowski_distance - euclidean distance와 manhattan distance의 일반화\n",
    "# p=1 이면 manhattan p=2이면 euclidean\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn.score(X_test, y_test) # 3일때 보다 더 좋은 accuracy를 갖게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6, p=2, weights='distance')\n",
    "# default는 uniform으로 가중치가 다 같다는 전제하에 있고\n",
    "# distance로 하면 우리ppt에 있는 거리의 역순으로 가중치를 부여하게 된다.\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "knn.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전보다 결과가 안좋은데 이유는 이미 정규화가 되어있고 교육용 데이터라 이상값이 별로 없기 때문이라고 생각한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
