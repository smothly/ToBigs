{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from scipy import io\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#서버 오류 -> 별도로 다운\n",
    "#mnist = fetch_mldata(\"MNIST original\")\n",
    "#X = mnist.data / 255.0\n",
    "#y = mnist.target\n",
    "\n",
    "#7만개의 작은 숫자 이미지\n",
    "#행 열이 반대로 되어있음 -> 전치\n",
    "mnist = io.loadmat('mnist-original.mat') \n",
    "X = mnist['data'].T\n",
    "y = mnist['label'].T\n",
    "\n",
    "# grayscale 28x28 pixel = 784 feature\n",
    "# 각 picel은 0~255의 값\n",
    "# label = 1~10\n",
    "\n",
    "print (X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y'] = y\n",
    "print('Size of the dataframe: {}'.format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 형태 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rndperm = np.random.permutation(df.shape[0])\n",
    "\n",
    "# Plot the graph\n",
    "plt.gray()\n",
    "fig = plt.figure( figsize=(16,7) )\n",
    "for i in range(0,15):\n",
    "    ax = fig.add_subplot(3,5,i+1, title=\"Digit: {}\".format(str(df.loc[rndperm[i],'y'])) )\n",
    "    ax.matshow(df.loc[rndperm[i],feat_cols].values.reshape((28,28)).astype(float))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist데이터를사용(8:2 비율로train set, test set split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10000개만\n",
    "X= df.loc[rndperm[:10000],:] \n",
    "y = X.pop('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train / test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 원본데이터 & PCA 축소데이터 & LDA 축소데이터 비교\n",
    "### 시각화 하기위해 2개의 feature로 차원축소 해보겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 원본데이터\n",
    "pd.DataFrame(X_train).head() #784개의 feature로 나타내진것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# test set을 transform 할때는 train의 fit으로 !\n",
    "pca = PCA(n_components=2) # n_components는 feature의 개수이다.\n",
    "\n",
    "%time pca.fit(X_train)\n",
    "\n",
    "%time X_train_pca = pd.DataFrame(pca.transform(X_train))\n",
    "%time X_test_pca = pd.DataFrame(pca.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.reset_index(inplace=True)\n",
    "del y_train['index']\n",
    "y_test.reset_index(inplace=True)\n",
    "del y_test['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_pca.shape, \n",
    "y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('First and Second Principal Components colored by digit', fontsize = 20)\n",
    "\n",
    "for i in range(10):\n",
    "    ax.scatter(X_train_pca[0][y_train['y']==i]\n",
    "               , X_train_pca[1][y_train['y']==i]\n",
    "               , s = 10)\n",
    "\n",
    "ax.legend(range(10))\n",
    "ax.grid()# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "\n",
    "%time lda.fit(X_train, y_train) # lda는 supervised learning으로 가장 분별정보가 높은 축을 찾아 차원축소 한다.\n",
    "\n",
    "%time X_train_lda = pd.DataFrame(lda.transform(X_train))\n",
    "%time X_test_lda = pd.DataFrame(lda.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_lda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('LDA 1', fontsize = 15)\n",
    "ax.set_ylabel('LDA 2', fontsize = 15)\n",
    "ax.set_title('First and Second LDA colored by digit', fontsize = 20)\n",
    "\n",
    "for i in range(10):\n",
    "    ax.scatter(X_train_lda[0][y_train['y']==i]\n",
    "            ,X_train_lda[1][y_train['y']==i]\n",
    "            , s = 10)\n",
    "\n",
    "ax.legend(range(10))\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지금까지배웠던다항분류기2개이상사용(KNN, random forest, NB 등등)\n",
    "## -timestamp 찍어서training시간과testaccuracy비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=10) # 숫자가 10개니까 10개로 분류해본다.\n",
    "\n",
    "%time knn.fit(X_train, y_train) \n",
    "print(\"ORIGINAL KNN SCORE:\", knn.score(X_test, y_test)) \n",
    "\n",
    "%time knn.fit(X_train_pca, y_train) \n",
    "print(\"PCA KNN SCORE:\", knn.score(X_test_pca, y_test)) \n",
    "\n",
    "%time knn.fit(X_train_lda, y_train) \n",
    "print(\"LDA KNN SCORE:\", knn.score(X_test_lda, y_test)) \n",
    "\n",
    "'''\n",
    "차원축소 안할경우 784개의 feature에 대해 거리를 전부 계산하기 때문에 시간이 30배이상으로 오래걸린다.\n",
    "PCA를 2차원으로 했을경우 0.4365\n",
    "LDA를 2차원으로 했을경우 0.5175 LDA가 조금 더 좋은이유는 지도학습 때문이라고 생각한다.\n",
    "'''\n",
    "\n",
    "#https://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "\n",
    "%time clf.fit(X_train, y_train)  \n",
    "print(\"ORIGINAL RF SCORE:\", clf.score(X_test, y_test)) \n",
    "\n",
    "%time clf.fit(X_train_pca, y_train)  \n",
    "print(\"ORIGINAL RF SCORE:\", clf.score(X_test_pca, y_test)) \n",
    "\n",
    "%time clf.fit(X_train_lda, y_train)  \n",
    "print(\"ORIGINAL RF SCORE:\", clf.score(X_test_lda, y_test)) \n",
    "\n",
    "# 출처: https://excelsior-cjh.tistory.com/166 [EXCELSIOR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "시간이 부족하여 다양한 하이퍼파라미터 튜닝이나 모델을 사용하지 못하고,\n",
    "차원축소를 다양한 개수로 해보지 못한 점이 아쉽습니다..... 다음엔 더 열심히 해보겠습니다..\n",
    "확실히 깨달은건 고차원의 데이터들을 다룰 수 있는 또 한가지의 방법을 배웠고\n",
    "고유값 분해, lda와 pca의 차이점등은 확실히 알았습니다! \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
